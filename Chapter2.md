# 多臂赌博机

**强化学习与其它机器学习方法最大的不同**:强化学习的训练信号是用评估给定动作的好坏的，而不是通过正确范例进行直接指导的。

- 评估性反馈：表明当前采取动作的好坏程度
- 指导性反馈：表明当前应采取的最好的动作

```我个人理解为评估性反馈是对过程的反馈，即基于某一个原则对每一个动作进行评价，而指导性反馈只是告诉你，你应该去做什么，而不说你当前做的与你应该做的之间的关系。举个例子，假设一道题是10分，你有其中一步做错了，评估性老师会告诉你当前得了7分，而指导性老师会告诉你，你得了0分。```

所以说，评估性反馈依赖于当前采取的动作，即采取不同的动作会得到不同的反馈；而指导性反馈则不依赖于当前采取的动作，即采取不同的动作也会得到相同的反馈。

本章节主要是通过讨论”K臂赌博机问题“，一个典型的非关联的评估性反馈问题来为之后的关联的完全强化学习问题做基础。

```非关联的：动作不会使环境发生改变。```

## 一个k臂赌博机问题

问题描述：重复在k个选项或动作中进行选择，每次选择会有一个收益，每个动作的收益服从一种分布。目标是在某一段时间内最大化总收益的期望。
我们称某种动作带来的收益的期望为这个动作的*价值*。
记 $t$ 时刻选择的动作为 $A_t$ ，收益为 $R_t$ ，任意动作 $a$ 的价值为 $q_*(a)$ ，即 $q_*(a) \dot= \mathbb{E}[R_t|A_t=a]$ 。
记动作 $a$ 在时刻 $t$ 的价值的估计为 $Q_t(a)$，我们期望 $Q_t(a)$ 接近 $q_*(a)$。

如果持续对动作的价值进行估计，那么在任一时刻都会至少有一个动作的估计价值是最高的，我们将这些对应最高估计价值的动作成为**贪心动作**。如果选择贪心动作，即称之为**开发**，如果不是基于贪心选择动作，而是随机选择动作，即为**试探**。
开发会最大化当前动作的收益，而试探则会带来总体收益的提升。
```这个很好理解，一个是守旧一个是创新，守旧会带来当前动作更为准确的价值估计，而创新则会提高其它动作的价值估计，从而准确得知当前动作相对于其它动作的价值估计。```
强化学习需要去解决的一个问题就是：**开发与试探的平衡**。
本文先不讨论如何去平衡开发与试探，而是通过实验验证：平衡优于贪心，也即*开发+试探>开发*。

